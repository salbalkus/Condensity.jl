var documenterSearchIndex = {"docs":
[{"location":"man/oracle/#Oracle-Density-Estimator","page":"Oracle Density Estimation using CausalTables.jl","title":"Oracle Density Estimator","text":"","category":"section"},{"location":"man/oracle/","page":"Oracle Density Estimation using CausalTables.jl","title":"Oracle Density Estimation using CausalTables.jl","text":"In some situations, the true conditional density is known, and we can use this information to estimate the conditional density. This is useful in settings where we have a known parametric form for the conditional density, but we don't know the parameters. It is especially useful for providing a \"ground truth\" in statistical simulations.","category":"page"},{"location":"man/oracle/","page":"Oracle Density Estimation using CausalTables.jl","title":"Oracle Density Estimation using CausalTables.jl","text":"OracleDensityEstimator","category":"page"},{"location":"man/oracle/#Condensity.OracleDensityEstimator","page":"Oracle Density Estimation using CausalTables.jl","title":"Condensity.OracleDensityEstimator","text":"mutable struct OracleDensityEstimator <: ConDensityEstimator\n\nAn \"oracle\" density estimator is a model that returns the true conditional density of a given variable.  Oracles are typically used for simulation and testing of methods that estimate conditional densities as nuisance parameters, in order to evaluate their performance when the underlying truth is known. They can also be used to compute a conditional density when the true underlying distribution of the data is known.\n\nConstructing an OracleDensityEstimator requires defining DataGeneratingProcess from the CausalTables package.  This object describes the true data generating process that is used to compute the true conditional density. Check out CausalTables for more information on how to define a DataGeneratingProcess,  and how to use it to conveniently generate data for statistical simulations.\n\nImportant Notes:\n\nWhen fitting the model, the data on which to condition is provided as the first input X, and the target variable is provided as the second input y.\nUnlike other MLJ models, both X and y must be in Table form when input to machine.\nThe predict method requires input as a Table containing the column names of both X and y that were provided during fitting.\n\nArguments\n\ndgp::DataGeneratingProcess: The data generating process used by the estimator, from the CausalTables package.\n\nExample\n\nusing Condensity\nusing MLJ\nusing CausalTables\n\n# Define a DataGeneratingProcess (DGP)\ndgp = DataGeneratingProcess([\n:X => (; O...) -> Normal(0, 1), \n:y => (; O...) -> Normal(3 * O[:X] + 3, 1)])\n\n# Construct an OracleDensityEstimator from the DGP\noracle = OracleDensityEstimator(dgp)\n\n# Construct data for testing\ndata = rand(dgp, 50)\nX = (X = Tables.getcolumn(data, :X),)\ny = (y = Tables.getcolumn(data, :y),)\n\n# Fit the OracleDensityEstimator to the data\n# Note that `data` contains both the columns of `X` and `y`\nmach = machine(oracle, data, y) |> fit!\n\n# Get predictions\npred = predict(mach, data)\n\n\n\n\n\n","category":"type"},{"location":"man/density/#Conditional-Density-Estimators","page":"Conditional Density Estimation","title":"Conditional Density Estimators","text":"","category":"section"},{"location":"man/density/","page":"Conditional Density Estimation","title":"Conditional Density Estimation","text":"Wraps KernelDensity.jl","category":"page"},{"location":"man/density/","page":"Conditional Density Estimation","title":"Conditional Density Estimation","text":"KDE(bandwidth::Float64, kernel::Type)","category":"page"},{"location":"man/density/","page":"Conditional Density Estimation","title":"Conditional Density Estimation","text":"LocationScaleDensity","category":"page"},{"location":"man/density/#Condensity.LocationScaleDensity","page":"Conditional Density Estimation","title":"Condensity.LocationScaleDensity","text":"LocationScaleDensity(location_model::MMI.Supervised, \n                     scale_model::MMI.Supervised, \n                     density_model::DensityEstimator, \n                     r_density, \n                     resampling::MT.ResamplingStrategy\n                     )\n\nA conditional density estimator that models the distribution of a target variable given a set of features.  Crucially, this model assumes that the conditional distribution depends only on the covariates through the distribution's first two moments: that is, the mean and variance. It works by:\n\nFitting a conditional mean (location) model and a conditional variance (scale) model for the target variable Y given the features X.\nStandardizing the target Y by subtracting the conditional mean and dividing by the square root of the conditional variance.\nPerforming kernel density estimation on the standardized residuals to estimate the conditional density.\n\nMathematically, this can be represented as the following steps:\n\nEstimate mu(X) = EYX using a supervised MLJ model.\nEstimate sigma^2(X) = VarYX using a supervised MLJ model.\nEstimate density rho(X) of (Y - hatmu(X))^2  hatsigma^2(X) using kernel smoothing.\nEstimate conditional density as p_n(YX) = hatrho((Y - hatmu(X)))  hatsigma(X)\n\nHence, constructing a LocationScaleDensity model requires defining three sub-models: a location model, a scale model, and a density model. In addition, a range object is required to tune the density model, and a resampling strategy is required to fit the sub-models.\n\nExample\n\nusing Condensity\nusing MLJ\nusing MLJLinearModels\n\n# generate regression model data\nn = 50\nX = randn(n)\ny = 4 .+ 2 .* X .+ randn(n)\n\n# put data in Tables.jl-compliant format\nX = (X = X,)\ny = (y = y,)\n\n# define and fit the model\nlocation_model = LinearRegressor()\nscale_model = ConstantRegressor()\ndensity_model = KDE(0.001)\n\nr = range(density_model, :bandwidth, lower=0.001, upper=0.5)\nlse_model = LocationScaleDensity(location_model, scale_model, density_model, r, CV(nfolds=10))\nlse_mach = machine(lse_model, X, y) |> fit!\n\n# Get predictions\ndata = merge(X, y) # must collect data into a single table\npredict(lse_mach, data)\n\nArguments\n\nlocation_model::MMI.Supervised: The location model used to estimate the conditional mean.\nscale_model::MMI.Supervised: The scale model used to estimate the conditional variance.\ndensity_model::DensityEstimator: The density model used to estimate the conditional density.\nr_density: An MLJ range object over which density_model will be tuned.\nresampling::MT.ResamplingStrategy: The resampling strategy used during model fitting.\n\n\n\n\n\n","category":"type"},{"location":"man/density-ratio/#Conditional-Density-Ratio-Estimators","page":"Conditional Density Ratio Estimation","title":"Conditional Density Ratio Estimators","text":"","category":"section"},{"location":"man/density-ratio/","page":"Conditional Density Ratio Estimation","title":"Conditional Density Ratio Estimation","text":"DensityRatioPlugIn","category":"page"},{"location":"man/density-ratio/#Condensity.DensityRatioPlugIn","page":"Conditional Density Ratio Estimation","title":"Condensity.DensityRatioPlugIn","text":"DensityRatioPlugIn(density_estimator::ConDensityEstimator, truncate::Bool = false)\n\nThis model estimates a conditional density ratio by directly fitting a conditional density model. DensityRatioPlugIn wraps the estimator and uses the fitted model to compute both the numerator and the denominator of the ratio.  That is, the model performs the following steps:\n\nEstimate p_n(YX) using a conditional density estimator.\nDirectly compute the density ratio H_n(X) = hatp_n(YX)  hatp_n(YX) by plugging in predictions from the fitted hatp_n(YX).\n\nArguments\n\ndensity_estimator::ConDensityEstimator: The density estimator used to compute the numerator and denominator of the density ratio.\ntruncate::Bool: Whether to truncate the density estimates to avoid numerical instability. Default: false.\n\nExample:\n\nusing Condensity\nusing MLJ\nusing MLJLinearModels\n\n# generate regression model data\nn = 50\nX = randn(n)\nY = 4 .+ 2 .* X .+ randn(n)\n\n# put data in Tables.jl-compliant format\nX = (X = X,)\ny = (y = Y,)\n\n# define the conditional density model\nlocation_model = LinearRegressor()\nscale_model = ConstantRegressor()\ndensity_model = KDE(0.001)\n\nr = range(density_model, :bandwidth, lower=0.001, upper=0.5)\nlse_model = LocationScaleDensity(location_model, scale_model, density_model, \n                                r, CV(nfolds=10))\n\n\n# plug in conditional density model and fit\ndr_model = DensityRatioPlugIn(lse_model)\ndr_mach = machine(dr_model, X, y) |> fit!\n\n# collect X and y for prediction\ndenominator = merge(X, y) \nnumerator = merge(X, (y = Y .- 0.1,))\n\npredict(dr_mach, numerator, denominator)\n\n\n\n\n\n","category":"type"},{"location":"man/density-ratio/","page":"Conditional Density Ratio Estimation","title":"Conditional Density Ratio Estimation","text":"DensityRatioClassifier","category":"page"},{"location":"man/density-ratio/#Condensity.DensityRatioClassifier","page":"Conditional Density Ratio Estimation","title":"Condensity.DensityRatioClassifier","text":"DensityRatioClassifier(classifier::MMI.Supervised, resampling::MT.ResamplingStrategy)\n\nThis model estimates a conditional density ratio using probabilistic classification. When predict is called, the following steps are performed:\n\nConstruct an augmented dataset by concatenating the data provided to the numerator and denominator data; that is, if the ratio is p_n(YX)  p_d(YX), then the augmented dataset is (X y Lambda) where Lambda is a binary variable indicating whether the observation is from the numerator.\nFit a supervised classifier MLJ model to predict P(Lambda = 1  Y X).\nApply Bayes' Theorem to compute the density ratio H_n(X) = fracp_n(YX)p_n(YX) as H_n(X) = fracP(Lambda = 1  Y X)1 - P(Lambda = 1  Y X) using the classifier's predictions.\n\nNotes:\n\nStrength: This model can be used to estimate the density ratio accurately in high-dimensional settings.\nWeakness: This model requires a supervised classifier to be trained for each call to predict, which can be computationally expensive if many calls to predict are expected.\n\nExample:\n\n```jldoctest; output = false, filter = r\"(?<=.{17}).*\"s using Condensity using MLJ using MLJLinearModels\n\nn = 50 X = randn(n) Y = 4 .+ 2 .* X .+ randn(n)\n\nX = (X = X,) y = (y = Y,)\n\nclassifiermodel = LogisticClassifier() drcmodel = DensityRatioClassifier(classifier_model, CV(nfolds = 10))\n\nnote that no data is needed for the machine, since training the model is only required for inference\n\ndrmach = machine(drcmodel, nothing, nothing) |> fit!\n\ncollect X and y for predicting the ratio between\n\ndensities of a shifted and unshifted dataset\n\ndenominator = merge(X, y)  numerator = merge(X, (y = Y .- 0.1,))\n\npredict(dr_mach, numerator, denominator)\n\noutput\n\n50-element Vector ``\n\nArguments\n\nclassifier::MMI.Supervised: The underlying supervised classifier used for density ratio estimation.\nresampling::MT.ResamplingStrategy: The resampling strategy used for training the classifier.\n\n\n\n\n\n","category":"type"},{"location":"man/getting-started/#Getting-Started","page":"Getting Started","title":"Getting Started","text":"","category":"section"},{"location":"man/getting-started/","page":"Getting Started","title":"Getting Started","text":"Coming soon.","category":"page"},{"location":"#Condensity.jl-Documentation","page":"Home","title":"Condensity.jl Documentation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A package for fitting conditional density estimation models using MLJ.","category":"page"},{"location":"#Purpose","page":"Home","title":"Purpose","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package provides methods for fitting both conditional density estimation (CDE) models and conditional density ratio estimation (CDRE) models in the MLJ machine learning framework. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Typical supervised learning regression models, such as linear regression, random forests, gradient boosters, and neural networks estimate all seek to estimate E(YX), the conditional expectation of some target Y. Conditional density estimators, on the other hand, seek to estimate f(YX), the entire density of Y given X (not just the mean). ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Conditional density estimators (and their ratios) are useful in a variety of settings, including propensity score estimation in causal inference, constructing prediction intervals, domain adaptation in machine learning, importance sampling, and other methods.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"CausalTables.jl can be installed using the Julia package manager. From the Julia REPL, type ] to enter the Pkg REPL mode and run","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pkg> add Condensity","category":"page"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Condensity.jl is designed to work with the MLJ machine learning framework. A typical MLJ workflow proceeds as follows:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Define the model and its hyperparameters.\nConstruct a machine that binds the model to the data.\nFit the model to the data using the fit! method.\nMake predictions using the predict method.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The models defined in Condensity.jl are compatible with many (but not all) MLJ functionalities, including hyperparameter tuning, cross-validation, and model composition.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Here's a simple example of how to fit a conditional density estimator using Condensity.jl:","category":"page"},{"location":"man/api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"man/api/","page":"API","title":"API","text":"The following documents public methods of Condensity.jl.","category":"page"},{"location":"man/api/","page":"API","title":"API","text":"Modules = [Condensity]\r\nOrder   = [:function, :type]","category":"page"},{"location":"man/api/#Condensity.bound-Tuple{Vector}","page":"API","title":"Condensity.bound","text":"bound(X::Vector; lower = -Inf, upper = Inf)\n\nBound the elements of a vector X within the specified lower and upper limits.\n\nArguments\n\nX::Vector: The input vector.\nlower::Real = -Inf: The lower limit for the elements of X.\nupper::Real = Inf: The upper limit for the elements of X.\n\nReturns\n\nX::Vector: The vector X with elements bounded within the specified limits.\n\n\n\n\n\n","category":"method"},{"location":"man/api/#Condensity.concat_tables-Tuple","page":"API","title":"Condensity.concat_tables","text":"concat_tables(tables...)\n\nConcatenates multiple tables into a single table by row.\n\nArguments\n\ntables: The tables to be concatenated.\n\nReturns\n\nA new table that is the row-wise concatenation of all input tables.\n\n\n\n\n\n","category":"method"},{"location":"man/api/#Condensity.meanloglik-Tuple{Any, Any}","page":"API","title":"Condensity.meanloglik","text":"meanloglik(y, ypred)\n\nCompute the mean log-likelihood between the observed values y and the predicted values ypred.\n\nArguments\n\ny: Observed values.\nypred: Predicted values.\n\nReturns\n\nThe mean log-likelihood.\n\n\n\n\n\n","category":"method"},{"location":"man/api/#Condensity.merge_tables-Tuple","page":"API","title":"Condensity.merge_tables","text":"merge_tables(tables...)\n\nMerge multiple tables into a single table by column-wise concatenation.\n\nArguments\n\ntables: The tables to be merged.\n\nReturns\n\nA merged table.\n\n\n\n\n\n","category":"method"},{"location":"man/api/#Condensity.negmeanloglik-Tuple{Any, Any}","page":"API","title":"Condensity.negmeanloglik","text":"negmeanloglik(y, ypred)\n\nCompute the negative mean log-likelihood between the observed values y and the predicted values ypred.\n\nArguments\n\ny: Observed values.\nypred: Predicted values.\n\nReturns\n\nThe negative mean log-likelihood.\n\n\n\n\n\n","category":"method"},{"location":"man/api/#Condensity.reject-Tuple{Any, Vararg{Any}}","page":"API","title":"Condensity.reject","text":"reject(data, symb...)\n\nRemove specified columns from a table.\n\nArguments\n\ndata: The input table.\nsymb...: Symbols representing the columns to be removed.\n\nReturns\n\nA new table with the specified columns removed.\n\n\n\n\n\n","category":"method"},{"location":"man/api/#MLJModelInterface.fit-Tuple{OracleDensityEstimator, Any, Any, Any}","page":"API","title":"MLJModelInterface.fit","text":"MMI.fit!(model::OracleDensityEstimator, verbosity, X, y)\n\nFit the OracleDensityEstimator model to the given data.\n\nArguments\n\nmodel::OracleDensityEstimator: The OracleDensityEstimator model to fit.\nverbosity: The verbosity level of the fitting process.\nX: The input data Table.\ny: The target data Table.\n\nReturns\n\nfitresult: A NamedTuple containing the fit result.\ncache: The cache object.\nreport: The report object.\n\n\n\n\n\n","category":"method"},{"location":"man/api/#MLJModelInterface.predict-Tuple{OracleDensityEstimator, Any, Any}","page":"API","title":"MLJModelInterface.predict","text":"MMI.predict(model::OracleDensityEstimator, verbosity, X)\n\nPredict the density using the OracleDensityEstimator model.\n\nArguments\n\nmodel::OracleDensityEstimator: The OracleDensityEstimator model to use for transformation.\nverbosity: The verbosity level.\nX: The input data table.\n\nReturns\n\ndensity: A Vector of density values.\n\n\n\n\n\n","category":"method"},{"location":"man/api/#Condensity.DensityRatioClassifier-Tuple{Supervised, ResamplingStrategy}","page":"API","title":"Condensity.DensityRatioClassifier","text":"DensityRatioClassifier(classifier::MMI.Supervised, resampling::MT.ResamplingStrategy)\n\nThis model estimates a conditional density ratio using probabilistic classification. When predict is called, the following steps are performed:\n\nConstruct an augmented dataset by concatenating the data provided to the numerator and denominator data; that is, if the ratio is p_n(YX)  p_d(YX), then the augmented dataset is (X y Lambda) where Lambda is a binary variable indicating whether the observation is from the numerator.\nFit a supervised classifier MLJ model to predict P(Lambda = 1  Y X).\nApply Bayes' Theorem to compute the density ratio H_n(X) = fracp_n(YX)p_n(YX) as H_n(X) = fracP(Lambda = 1  Y X)1 - P(Lambda = 1  Y X) using the classifier's predictions.\n\nNotes:\n\nStrength: This model can be used to estimate the density ratio accurately in high-dimensional settings.\nWeakness: This model requires a supervised classifier to be trained for each call to predict, which can be computationally expensive if many calls to predict are expected.\n\nExample:\n\n```jldoctest; output = false, filter = r\"(?<=.{17}).*\"s using Condensity using MLJ using MLJLinearModels\n\nn = 50 X = randn(n) Y = 4 .+ 2 .* X .+ randn(n)\n\nX = (X = X,) y = (y = Y,)\n\nclassifiermodel = LogisticClassifier() drcmodel = DensityRatioClassifier(classifier_model, CV(nfolds = 10))\n\nnote that no data is needed for the machine, since training the model is only required for inference\n\ndrmach = machine(drcmodel, nothing, nothing) |> fit!\n\ncollect X and y for predicting the ratio between\n\ndensities of a shifted and unshifted dataset\n\ndenominator = merge(X, y)  numerator = merge(X, (y = Y .- 0.1,))\n\npredict(dr_mach, numerator, denominator)\n\noutput\n\n50-element Vector ``\n\nArguments\n\nclassifier::MMI.Supervised: The underlying supervised classifier used for density ratio estimation.\nresampling::MT.ResamplingStrategy: The resampling strategy used for training the classifier.\n\n\n\n\n\n","category":"method"},{"location":"man/api/#Condensity.DensityRatioPlugIn","page":"API","title":"Condensity.DensityRatioPlugIn","text":"DensityRatioPlugIn(density_estimator::ConDensityEstimator, truncate::Bool = false)\n\nThis model estimates a conditional density ratio by directly fitting a conditional density model. DensityRatioPlugIn wraps the estimator and uses the fitted model to compute both the numerator and the denominator of the ratio.  That is, the model performs the following steps:\n\nEstimate p_n(YX) using a conditional density estimator.\nDirectly compute the density ratio H_n(X) = hatp_n(YX)  hatp_n(YX) by plugging in predictions from the fitted hatp_n(YX).\n\nArguments\n\ndensity_estimator::ConDensityEstimator: The density estimator used to compute the numerator and denominator of the density ratio.\ntruncate::Bool: Whether to truncate the density estimates to avoid numerical instability. Default: false.\n\nExample:\n\nusing Condensity\nusing MLJ\nusing MLJLinearModels\n\n# generate regression model data\nn = 50\nX = randn(n)\nY = 4 .+ 2 .* X .+ randn(n)\n\n# put data in Tables.jl-compliant format\nX = (X = X,)\ny = (y = Y,)\n\n# define the conditional density model\nlocation_model = LinearRegressor()\nscale_model = ConstantRegressor()\ndensity_model = KDE(0.001)\n\nr = range(density_model, :bandwidth, lower=0.001, upper=0.5)\nlse_model = LocationScaleDensity(location_model, scale_model, density_model, \n                                r, CV(nfolds=10))\n\n\n# plug in conditional density model and fit\ndr_model = DensityRatioPlugIn(lse_model)\ndr_mach = machine(dr_model, X, y) |> fit!\n\n# collect X and y for prediction\ndenominator = merge(X, y) \nnumerator = merge(X, (y = Y .- 0.1,))\n\npredict(dr_mach, numerator, denominator)\n\n\n\n\n\n","category":"type"},{"location":"man/api/#Condensity.KDE-Tuple{Float64, Distributions.Distribution}","page":"API","title":"Condensity.KDE","text":"KDE(bandwidth::Float64, kernel::Function)\n\nWraps the Kernel Density Estimator from KernelDensity.jl as an MLJ object.  This model defines a density estimator that does not condition on any features, and is used to estimate the marginal density of a target variable. It is mostly used as a component of a LocationScaleDensity model, though it can be used on its own.\n\nFor more information on Kernel Density Estimation, see here.\n\nArguments\n\nbandwidth::Float64: The bandwidth parameter for the KDE.\nkernel: The kernel function used for the KDE. Default: Epanechnikov.\n\nExample:\n\n\nusing Condensity\n\n# Generate data in Tables.jl-compliant format\nX = (X = randn(10),)\n\n# define and fit the model\nkde = KDE(1.0)\nkde_mach = machine(kde, X) |> fit!\npredict(kde_mach, X)\n\n\n\n\n\n","category":"method"},{"location":"man/api/#Condensity.KDE-Tuple{Float64, Function}","page":"API","title":"Condensity.KDE","text":"KDE(bandwidth::Float64, kernel::Function)\n\nWraps the Kernel Density Estimator from KernelDensity.jl as an MLJ object.  This model defines a density estimator that does not condition on any features, and is used to estimate the marginal density of a target variable. It is mostly used as a component of a LocationScaleDensity model, though it can be used on its own.\n\nFor more information on Kernel Density Estimation, see here.\n\nArguments\n\nbandwidth::Float64: The bandwidth parameter for the KDE.\nkernel: The kernel function used for the KDE. Default: Epanechnikov.\n\nExample:\n\n\nusing Condensity\n\n# Generate data in Tables.jl-compliant format\nX = (X = randn(10),)\n\n# define and fit the model\nkde = KDE(1.0)\nkde_mach = machine(kde, X) |> fit!\npredict(kde_mach, X)\n\n\n\n\n\n","category":"method"},{"location":"man/api/#Condensity.KDE-Tuple{Float64, Type}","page":"API","title":"Condensity.KDE","text":"KDE(bandwidth::Float64, kernel::Type)\n\nWraps the Kernel Density Estimator from KernelDensity.jl as an MLJ object.  This model defines a density estimator that does not condition on any features, and is used to estimate the marginal density of a target variable. It is mostly used as a component of a LocationScaleDensity model, though it can be used on its own.\n\nFor more information on Kernel Density Estimation, see here.\n\nArguments\n\nbandwidth::Float64: The bandwidth parameter for the KDE.\nkernel: The kernel function used for the KDE. Default: Epanechnikov.\n\nExample\n\nusing Condensity\nusing MLJ\n\n# Generate data in Tables.jl-compliant format\nX = (X = randn(10),)\n\n# define and fit the model\nkde = KDE(1.0, Epanechnikov)\nkde_mach = machine(kde, X) |> fit!\npredict(kde_mach, X)\n\n\n\n\n\n","category":"method"},{"location":"man/api/#Condensity.LocationScaleDensity-Tuple{Supervised, Supervised, Condensity.DensityEstimator, Any, ResamplingStrategy}","page":"API","title":"Condensity.LocationScaleDensity","text":"LocationScaleDensity(location_model::MMI.Supervised, \n                     scale_model::MMI.Supervised, \n                     density_model::DensityEstimator, \n                     r_density, \n                     resampling::MT.ResamplingStrategy\n                     )\n\nA conditional density estimator that models the distribution of a target variable given a set of features.  Crucially, this model assumes that the conditional distribution depends only on the covariates through the distribution's first two moments: that is, the mean and variance. It works by:\n\nFitting a conditional mean (location) model and a conditional variance (scale) model for the target variable Y given the features X.\nStandardizing the target Y by subtracting the conditional mean and dividing by the square root of the conditional variance.\nPerforming kernel density estimation on the standardized residuals to estimate the conditional density.\n\nMathematically, this can be represented as the following steps:\n\nEstimate mu(X) = EYX using a supervised MLJ model.\nEstimate sigma^2(X) = VarYX using a supervised MLJ model.\nEstimate density rho(X) of (Y - hatmu(X))^2  hatsigma^2(X) using kernel smoothing.\nEstimate conditional density as p_n(YX) = hatrho((Y - hatmu(X)))  hatsigma(X)\n\nHence, constructing a LocationScaleDensity model requires defining three sub-models: a location model, a scale model, and a density model. In addition, a range object is required to tune the density model, and a resampling strategy is required to fit the sub-models.\n\nExample\n\nusing Condensity\nusing MLJ\nusing MLJLinearModels\n\n# generate regression model data\nn = 50\nX = randn(n)\ny = 4 .+ 2 .* X .+ randn(n)\n\n# put data in Tables.jl-compliant format\nX = (X = X,)\ny = (y = y,)\n\n# define and fit the model\nlocation_model = LinearRegressor()\nscale_model = ConstantRegressor()\ndensity_model = KDE(0.001)\n\nr = range(density_model, :bandwidth, lower=0.001, upper=0.5)\nlse_model = LocationScaleDensity(location_model, scale_model, density_model, r, CV(nfolds=10))\nlse_mach = machine(lse_model, X, y) |> fit!\n\n# Get predictions\ndata = merge(X, y) # must collect data into a single table\npredict(lse_mach, data)\n\nArguments\n\nlocation_model::MMI.Supervised: The location model used to estimate the conditional mean.\nscale_model::MMI.Supervised: The scale model used to estimate the conditional variance.\ndensity_model::DensityEstimator: The density model used to estimate the conditional density.\nr_density: An MLJ range object over which density_model will be tuned.\nresampling::MT.ResamplingStrategy: The resampling strategy used during model fitting.\n\n\n\n\n\n","category":"method"},{"location":"man/api/#Condensity.OracleDensityEstimator-Tuple{CausalTables.DataGeneratingProcess}","page":"API","title":"Condensity.OracleDensityEstimator","text":"mutable struct OracleDensityEstimator <: ConDensityEstimator\n\nAn \"oracle\" density estimator is a model that returns the true conditional density of a given variable.  Oracles are typically used for simulation and testing of methods that estimate conditional densities as nuisance parameters, in order to evaluate their performance when the underlying truth is known. They can also be used to compute a conditional density when the true underlying distribution of the data is known.\n\nConstructing an OracleDensityEstimator requires defining DataGeneratingProcess from the CausalTables package.  This object describes the true data generating process that is used to compute the true conditional density. Check out CausalTables for more information on how to define a DataGeneratingProcess,  and how to use it to conveniently generate data for statistical simulations.\n\nImportant Notes:\n\nWhen fitting the model, the data on which to condition is provided as the first input X, and the target variable is provided as the second input y.\nUnlike other MLJ models, both X and y must be in Table form when input to machine.\nThe predict method requires input as a Table containing the column names of both X and y that were provided during fitting.\n\nArguments\n\ndgp::DataGeneratingProcess: The data generating process used by the estimator, from the CausalTables package.\n\nExample\n\nusing Condensity\nusing MLJ\nusing CausalTables\n\n# Define a DataGeneratingProcess (DGP)\ndgp = DataGeneratingProcess([\n:X => (; O...) -> Normal(0, 1), \n:y => (; O...) -> Normal(3 * O[:X] + 3, 1)])\n\n# Construct an OracleDensityEstimator from the DGP\noracle = OracleDensityEstimator(dgp)\n\n# Construct data for testing\ndata = rand(dgp, 50)\nX = (X = Tables.getcolumn(data, :X),)\ny = (y = Tables.getcolumn(data, :y),)\n\n# Fit the OracleDensityEstimator to the data\n# Note that `data` contains both the columns of `X` and `y`\nmach = machine(oracle, data, y) |> fit!\n\n# Get predictions\npred = predict(mach, data)\n\n\n\n\n\n","category":"method"}]
}
